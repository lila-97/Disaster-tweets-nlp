{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe33aa8",
   "metadata": {},
   "source": [
    "# Project: Disaster Tweets \n",
    "\n",
    "Twitter has become an important communication channel in times of emergency.\n",
    "The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n",
    "\n",
    "But, it’s not always clear whether a person’s words are actually announcing a disaster. \n",
    "\n",
    "In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367dac4",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebd3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import tensorflow \n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Input, Dense \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c361abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\elisa\\\\OneDrive\\\\Desktop\\\\MACHINE LEARNING\\\\PROJECT_ML'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1a234",
   "metadata": {},
   "source": [
    "## Loading the data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35aa6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets \n",
    "\n",
    "url = 'https://www.math.unipd.it/~dasan/disaster/'\n",
    "train_df = pd.read_csv(url + 'train.csv', sep=\",\") \n",
    "test_df = pd.read_csv(url + 'test.csv', sep=\",\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c764c59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a499d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape # The trianing set has 7613 rows and 5 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4bad69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The real disaster tweets are 3271\n",
      "The fake disaster tweets are 4342\n",
      "\n",
      "Hence, the two classes are balanced, although we have slightly more fake than real tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"The real disaster tweets are {}\".format(len(train_df[train_df['target'] == 1])))\n",
    "print(\"The fake disaster tweets are {}\".format(len(train_df[train_df['target'] == 0])))\n",
    "print()\n",
    "print(\"Hence, the two classes are balanced, although we have slightly more fake than real tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce46fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing values for the keyword column are: 61\n",
      "There are 222 unique keywords in the dataframe\n",
      "\n",
      "The missing values for the location column are: 2533\n",
      "There are 3342 unique locations in the dataframe\n",
      "\n",
      "One can already assume that keywords are going to be more relevant than locations for classification, \n",
      "      as more than 30% of location values are missing\n"
     ]
    }
   ],
   "source": [
    "print(\"The missing values for the keyword column are: {}\".format(train_df[\"keyword\"].isna().sum()))\n",
    "print(\"There are {} unique keywords in the dataframe\".format(len(train_df[\"keyword\"].unique())))\n",
    "print()\n",
    "print(\"The missing values for the location column are: {}\".format(train_df[\"location\"].isna().sum()))\n",
    "print(\"There are {} unique locations in the dataframe\".format(len(train_df[\"location\"].unique())))\n",
    "print()\n",
    "print(\"\"\"One can already assume that keywords are going to be more relevant than locations for classification, \n",
    "      as more than 30% of location values are missing\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d3bf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>79</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>USA</td>\n",
       "      <td>#Kurds trampling on Turkmen flag later set it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>287</td>\n",
       "      <td>ambulance</td>\n",
       "      <td>USA</td>\n",
       "      <td>Twelve feared killed in Pakistani air ambulanc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>316</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>USA</td>\n",
       "      <td>One thing for sure-God has promised Israel wil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>461</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>USA</td>\n",
       "      <td>YOUR PHONE IS SPYING ON YOU! Hidden Back Door ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>551</td>\n",
       "      <td>arson</td>\n",
       "      <td>USA</td>\n",
       "      <td>Thousands attend a rally organized by Peace No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>10511</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>USA</td>\n",
       "      <td>The Latest: Washington #Wildfire misses town; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7356</th>\n",
       "      <td>10533</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>USA</td>\n",
       "      <td>The Latest: #Wildfire destroys more homes but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413</th>\n",
       "      <td>10606</td>\n",
       "      <td>wounded</td>\n",
       "      <td>USA</td>\n",
       "      <td>One man fatally shot another wounded on Vermon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7420</th>\n",
       "      <td>10613</td>\n",
       "      <td>wounded</td>\n",
       "      <td>USA</td>\n",
       "      <td>Police Officer Wounded Suspect Dead After Exch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>10628</td>\n",
       "      <td>wounded</td>\n",
       "      <td>USA</td>\n",
       "      <td>ABC News: Police Officer Wounded Suspect Dead ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      keyword location  \\\n",
       "55       79       ablaze      USA   \n",
       "203     287    ambulance      USA   \n",
       "223     316  annihilated      USA   \n",
       "316     461   armageddon      USA   \n",
       "382     551        arson      USA   \n",
       "...     ...          ...      ...   \n",
       "7341  10511     wildfire      USA   \n",
       "7356  10533     wildfire      USA   \n",
       "7413  10606      wounded      USA   \n",
       "7420  10613      wounded      USA   \n",
       "7430  10628      wounded      USA   \n",
       "\n",
       "                                                   text  target  \n",
       "55    #Kurds trampling on Turkmen flag later set it ...       1  \n",
       "203   Twelve feared killed in Pakistani air ambulanc...       1  \n",
       "223   One thing for sure-God has promised Israel wil...       0  \n",
       "316   YOUR PHONE IS SPYING ON YOU! Hidden Back Door ...       0  \n",
       "382   Thousands attend a rally organized by Peace No...       1  \n",
       "...                                                 ...     ...  \n",
       "7341  The Latest: Washington #Wildfire misses town; ...       1  \n",
       "7356  The Latest: #Wildfire destroys more homes but ...       1  \n",
       "7413  One man fatally shot another wounded on Vermon...       1  \n",
       "7420  Police Officer Wounded Suspect Dead After Exch...       1  \n",
       "7430  ABC News: Police Officer Wounded Suspect Dead ...       1  \n",
       "\n",
       "[104 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"location\"] == 'USA'] ##location is 'USA' in 104 tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496bb9f",
   "metadata": {},
   "source": [
    "# Natural Language Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae1bd9",
   "metadata": {},
   "source": [
    "## Preprocessing phase "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a842c4",
   "metadata": {},
   "source": [
    "First, we look at the text of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55975d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = train_df[\"text\"]\n",
    "\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371b1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 110 tweets which are repeated in the dataframe and 7503 unique tweets\n"
     ]
    }
   ],
   "source": [
    "len(text_df.unique())\n",
    "\n",
    "print(\"There are 110 tweets which are repeated in the dataframe and 7503 unique tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484e8c2",
   "metadata": {},
   "source": [
    "Then, we make a list of all the words which will be useless for classification, i.e. those words which give us no indication about the realness of the disaster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83654abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2cb5c",
   "metadata": {},
   "source": [
    "## Cleaning the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d890c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for cleaning text of tweets \n",
    "\n",
    "def stopword_remover(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
    "\n",
    "def url_remover(text):\n",
    "    text1 = re.sub(r'http?:\\/\\/.*[\\r\\n]*', \"\", text)\n",
    "    text2 = re.sub(r'https:\\/\\/.*[\\r\\n]*', \"\", text1)\n",
    "    text3 = \" \".join(word for word in text2.split() if not word.startswith('@'))\n",
    "    return text3.casefold().strip()\n",
    "\n",
    "def special_chars_remover(text):\n",
    "    text1 = re.sub(r\"[^a-zA\\s]\", \"\", text)\n",
    "    text2 = text1.replace(\"#\", \"\").strip()\n",
    "    return text2.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ec550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying functions to the training and test sets \n",
    "\n",
    "train_df[\"text\"] = train_df.text.apply(url_remover).dropna()\n",
    "test_df[\"text\"] = test_df.text.apply(url_remover)\n",
    "\n",
    "train_df[\"text\"] = train_df.text.apply(stopword_remover).dropna()\n",
    "test_df[\"text\"] = test_df.text.apply(stopword_remover)\n",
    "\n",
    "train_df[\"text\"] = train_df.text.apply(special_chars_remover).dropna()\n",
    "test_df[\"text\"] = test_df.text.apply(special_chars_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7efa1299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN       deeds reason earthquake may allah forgive us   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  residents asked shelter place notified officer...   \n",
       "3   6     NaN      NaN  people receive wildfires evacuation orders cal...   \n",
       "4   7     NaN      NaN  got sent photo ruby alaska smoke wildfires pou...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3219220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                forest fire near la ronge sask canada\n",
      "2    residents asked shelter place notified officer...\n",
      "3    people receive wildfires evacuation orders cal...\n",
      "4    got sent photo ruby alaska smoke wildfires pou...\n",
      "5    rockyfire update  california hwy  closed direc...\n",
      "6    flood disaster heavy rain causes flash floodin...\n",
      "7                           im top hill see fire woods\n",
      "8    theres emergency evacuation happening building...\n",
      "9                        im afraid tornado coming area\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df['text'][1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eebb17",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fda6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is useless if I use CountVectorizer, does it automatically \n",
    "\n",
    "#from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "#text = train_df['text']\n",
    "\n",
    "#text = text.apply(nltk.wordpunct_tokenize)\n",
    "\n",
    "#text.head()\n",
    "\n",
    "#train_df['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cbb6d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding bridge collapse nearb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control wild fires california even northern pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m  utckm volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating ebike collided car little...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>latest homes razed northern california wildfir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "7608  two giant cranes holding bridge collapse nearb...       1  \n",
       "7609  control wild fires california even northern pa...       1  \n",
       "7610                            m  utckm volcano hawaii       1  \n",
       "7611  police investigating ebike collided car little...       1  \n",
       "7612  latest homes razed northern california wildfir...       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80400553",
   "metadata": {},
   "source": [
    "## Linear modeling \n",
    "\n",
    "best performance (3-fold CV and tf-idf transformation on single word counts): 0.63% \n",
    "\n",
    "### IDEAS IF PERFORMANCE IS BAD: \n",
    "\n",
    "* Try stemming \n",
    "* Try lemmatization \n",
    "* Try TF or TF-IDF representation \n",
    "* Try one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f7a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to convert our text into a machine-readable format \n",
    "# We use BOW approach  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d87c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction \n",
    "\n",
    "\n",
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "tfidf_vectorizer = feature_extraction.text.TfidfTransformer()\n",
    "\n",
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "train_vectors = tfidf_vectorizer.fit_transform(train_vectors)\n",
    "\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])\n",
    "test_vectors = tfidf_vectorizer.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b08fad7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14244)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors[0].todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cf84c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, model_selection\n",
    "\n",
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c50b43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60056338, 0.54910243, 0.63347023])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce680816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
