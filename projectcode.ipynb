{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe33aa8",
   "metadata": {},
   "source": [
    "# Project: Disaster Tweets \n",
    "\n",
    "Twitter has become an important communication channel in times of emergency.\n",
    "The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n",
    "\n",
    "But, it’s not always clear whether a person’s words are actually announcing a disaster. \n",
    "\n",
    "In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367dac4",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cebd3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import tensorflow \n",
    "import nltk\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Input, Dense \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c361abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\elisa\\\\OneDrive\\\\Desktop\\\\MACHINE LEARNING\\\\PROJECT_ML'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace1a234",
   "metadata": {},
   "source": [
    "## Loading the data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35aa6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets \n",
    "\n",
    "url = 'https://www.math.unipd.it/~dasan/disaster/'\n",
    "train_df = pd.read_csv(url + 'train.csv', sep=\",\") \n",
    "test_df = pd.read_csv(url + 'test.csv', sep=\",\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c764c59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a499d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape # The trianing set has 7613 rows and 5 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d4bad69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The real disaster tweets are 3271\n",
      "The fake disaster tweets are 4342\n",
      "\n",
      "Hence, the two classes are balanced, although we have slightly more fake than real tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"The real disaster tweets are {}\".format(len(train_df[train_df['target'] == 1])))\n",
    "print(\"The fake disaster tweets are {}\".format(len(train_df[train_df['target'] == 0])))\n",
    "print()\n",
    "print(\"Hence, the two classes are balanced, although we have slightly more fake than real tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ce46fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing values for the keyword column are: 61\n",
      "There are 222 unique keywords in the dataframe\n",
      "\n",
      "The missing values for the location column are: 2533\n",
      "There are 3342 unique locations in the dataframe\n",
      "\n",
      "One can already assume that keywords are going to be more relevant than locations for classification, \n",
      "      as more than 30% of location values are missing\n"
     ]
    }
   ],
   "source": [
    "print(\"The missing values for the keyword column are: {}\".format(train_df[\"keyword\"].isna().sum()))\n",
    "print(\"There are {} unique keywords in the dataframe\".format(len(train_df[\"keyword\"].unique())))\n",
    "print()\n",
    "print(\"The missing values for the location column are: {}\".format(train_df[\"location\"].isna().sum()))\n",
    "print(\"There are {} unique locations in the dataframe\".format(len(train_df[\"location\"].unique())))\n",
    "print()\n",
    "print(\"\"\"One can already assume that keywords are going to be more relevant than locations for classification, \n",
    "      as more than 30% of location values are missing\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12d3bf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>79</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>USA</td>\n",
       "      <td>#Kurds trampling on Turkmen flag later set it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>287</td>\n",
       "      <td>ambulance</td>\n",
       "      <td>USA</td>\n",
       "      <td>Twelve feared killed in Pakistani air ambulanc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>316</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>USA</td>\n",
       "      <td>One thing for sure-God has promised Israel wil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>461</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>USA</td>\n",
       "      <td>YOUR PHONE IS SPYING ON YOU! Hidden Back Door ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>551</td>\n",
       "      <td>arson</td>\n",
       "      <td>USA</td>\n",
       "      <td>Thousands attend a rally organized by Peace No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>10511</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>USA</td>\n",
       "      <td>The Latest: Washington #Wildfire misses town; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7356</th>\n",
       "      <td>10533</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>USA</td>\n",
       "      <td>The Latest: #Wildfire destroys more homes but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7413</th>\n",
       "      <td>10606</td>\n",
       "      <td>wounded</td>\n",
       "      <td>USA</td>\n",
       "      <td>One man fatally shot another wounded on Vermon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7420</th>\n",
       "      <td>10613</td>\n",
       "      <td>wounded</td>\n",
       "      <td>USA</td>\n",
       "      <td>Police Officer Wounded Suspect Dead After Exch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>10628</td>\n",
       "      <td>wounded</td>\n",
       "      <td>USA</td>\n",
       "      <td>ABC News: Police Officer Wounded Suspect Dead ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      keyword location  \\\n",
       "55       79       ablaze      USA   \n",
       "203     287    ambulance      USA   \n",
       "223     316  annihilated      USA   \n",
       "316     461   armageddon      USA   \n",
       "382     551        arson      USA   \n",
       "...     ...          ...      ...   \n",
       "7341  10511     wildfire      USA   \n",
       "7356  10533     wildfire      USA   \n",
       "7413  10606      wounded      USA   \n",
       "7420  10613      wounded      USA   \n",
       "7430  10628      wounded      USA   \n",
       "\n",
       "                                                   text  target  \n",
       "55    #Kurds trampling on Turkmen flag later set it ...       1  \n",
       "203   Twelve feared killed in Pakistani air ambulanc...       1  \n",
       "223   One thing for sure-God has promised Israel wil...       0  \n",
       "316   YOUR PHONE IS SPYING ON YOU! Hidden Back Door ...       0  \n",
       "382   Thousands attend a rally organized by Peace No...       1  \n",
       "...                                                 ...     ...  \n",
       "7341  The Latest: Washington #Wildfire misses town; ...       1  \n",
       "7356  The Latest: #Wildfire destroys more homes but ...       1  \n",
       "7413  One man fatally shot another wounded on Vermon...       1  \n",
       "7420  Police Officer Wounded Suspect Dead After Exch...       1  \n",
       "7430  ABC News: Police Officer Wounded Suspect Dead ...       1  \n",
       "\n",
       "[104 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"location\"] == 'USA'] ##location is 'USA' in 104 tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496bb9f",
   "metadata": {},
   "source": [
    "# Natural Language Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae1bd9",
   "metadata": {},
   "source": [
    "## Preprocessing phase "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a842c4",
   "metadata": {},
   "source": [
    "First, we look at the text of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55975d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = train_df[\"text\"]\n",
    "\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "371b1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 110 tweets which are repeated in the dataframe and 7503 unique tweets\n"
     ]
    }
   ],
   "source": [
    "len(text_df.unique())\n",
    "\n",
    "print(\"There are 110 tweets which are repeated in the dataframe and 7503 unique tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484e8c2",
   "metadata": {},
   "source": [
    "Then, we make a list of all the words which will be useless for classification, i.e. those words which give us no indication about the realness of the disaster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "83654abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = ['a', 'an', 'the', 'and','it', 'for', 'or', 'but', 'in', 'my', 'your', 'our', 'their',\n",
    "                 'mine', 'yours', 'ours', 'theirs', 'what', 'when', 'how', 'why', 'when', 'about', 'actually', \n",
    "                  'almost', 'also', 'although', 'always', 'am', 'any', 'are', 'as', 'at', 'be', 'became', 'become',\n",
    "                  'but', 'by', 'can', 'could', 'did', 'do', 'does', 'each', 'either', 'else', 'for', \n",
    "                  'from', 'had', 'got', 'get', 'done', 'none', 'do', 'does', 'doing', 'being', 'people',\n",
    "                  'has', 'have', 'hence', 'how', 'i','I', 'if', 'is', 'it', 'its', 'just', 'may', 'maybe', 'me', 'might',\n",
    "                  'must', 'neither', 'nor', 'not', 'of', 'oh', 'ok', 'where', 'whereas', 'wherever', 'whenever', \n",
    "                  'whether', 'which','while', 'who', 'whom', 'whoever', 'whose', 'will', 'with', 'within', 'without', \n",
    "                  'would', 'yes', 'yet', 'you', 'youd', 'youll', 'youre', 'y', 'youve', 'yourself', 'yourselves', 'us', \n",
    "                  'this', 'that', 'those', 'some','all']\n",
    "\n",
    "stopwords = set(list_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2cb5c",
   "metadata": {},
   "source": [
    "Then, we write some functions for cleaning the text of the tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39d890c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for cleaning text of tweets \n",
    "\n",
    "def stopword_remover(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in stopwords])\n",
    "\n",
    "def url_remover(text):\n",
    "    text1 = re.sub(r'http?:\\/\\/.*[\\r\\n]*', \"\", text)\n",
    "    text2 = re.sub(r'https:\\/\\/.*[\\r\\n]*', \"\", text1)\n",
    "    text3 = \" \".join(word for word in text2.split() if not word.startswith('@'))\n",
    "    return text3.casefold().strip()\n",
    "\n",
    "def special_chars_remover(text):\n",
    "    text1 = re.sub(r\"[^a-zA\\s]\", \"\", text)\n",
    "    text2 = text1.replace(\"#\", \"\").strip()\n",
    "    return text2.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49ec550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying functions to the training and test sets \n",
    "\n",
    "train_df[\"text\"] = train_df.text.apply(url_remover).dropna()\n",
    "test_df[\"text\"] = test_df.text.apply(url_remover)\n",
    "\n",
    "train_df[\"text\"] = train_df.text.apply(stopword_remover).dropna()\n",
    "test_df[\"text\"] = test_df.text.apply(stopword_remover)\n",
    "\n",
    "train_df[\"text\"] = train_df.text.apply(special_chars_remover).dropna()\n",
    "test_df[\"text\"] = test_df.text.apply(special_chars_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7efa1299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake allah forgive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked to shelter place notified offi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>receive wildfires evacuation orders california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sent photo ruby alaska smoke wildfires pours i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN              deeds reason earthquake allah forgive   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  residents asked to shelter place notified offi...   \n",
       "3   6     NaN      NaN     receive wildfires evacuation orders california   \n",
       "4   7     NaN      NaN  sent photo ruby alaska smoke wildfires pours i...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3219220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16120e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
